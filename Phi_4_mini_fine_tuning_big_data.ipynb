{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuned Phi-4 Model with Unsloth\n",
        "\n",
        "This model was fine-tuned using the Phi-4 architecture and the Unsloth library.  \n",
        "The dataset was converted into the appropriate format for instruction tuning.  \n",
        "The final model is saved and stored in Google Drive for future use.\n"
      ],
      "metadata": {
        "id": "mmt8z9JvO3No"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFDWn8_4nnzN"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qmv1oRcWnnzN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSSl0mKOb8sv",
        "outputId": "b331d458-ed89-43db-b42f-7ed6ae5b1a29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpSuqscNnnzO"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QmUBVEnvCDJv",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "d61846e6c58e46719c2f74760fa02871",
            "3b9d90c4e3054059af225683025c2b3a",
            "cb2f3f61c06c4781936194ab86fc210e",
            "54f3113b4b4648649a6319405aebaa98",
            "c288924e814b4e5384cbe8db750270f8",
            "8177bf13a6094797959d4fc7c630d52a",
            "64252cef56984119938d8cf35c600199",
            "f31d49fc7dbc4d16a60da369ff27aab5",
            "2269879049da4663a0ab2da8ce3174e1",
            "19893acc6a5d4d7fb26781d44fbc37ad",
            "135dcf1fb51a4aa68ee20428386129ab"
          ]
        },
        "outputId": "0bebcabb-e6f5-4181-be35-b1d9f729ed0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.5.1: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d61846e6c58e46719c2f74760fa02871"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel  # FastVisionModel for LLMs\n",
        "import torch\n",
        "max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
        "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Phi-4\",  # Phi-4 2x faster!\n",
        "    \"unsloth/Phi-4-unsloth-bnb-4bit\",  # Phi-4 Unsloth Dynamic 4-bit Quant\n",
        "]  # More models at https://docs.unsloth.ai/get-started/all-our-models\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Phi-4\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters for parameter efficient finetuning - this allows us to only efficiently train 1% of all parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6bZsfBuZDeCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b7e384-1317-4ecc-cf75-9b7c6f50d8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.5.1 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the `Phi-4` format for conversation style finetunes. But we convert it to HuggingFace's normal multiturn format `(\"role\", \"content\")` instead of `(\"from\", \"value\")`/ Phi-4 renders multi turn conversations like below:\n",
        "\n",
        "```\n",
        "<|im_start|>user<|im_sep|>Hello!<|im_end|>\n",
        "<|im_start|>assistant<|im_sep|>Hi! How can I help?<|im_end|>\n",
        "<|im_start|>user<|im_sep|>What is 2+2?<|im_end|>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"/content/dataset.xlsx\")\n"
      ],
      "metadata": {
        "id": "jGbH9R3Gp747"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "\n",
        "# Her soru-cevap Ã§iftini formatla ve JSONL satÄ±rÄ± olarak hazÄ±rla\n",
        "lines = []\n",
        "for _, row in df.iterrows():\n",
        "    question = str(row['Question']).strip()\n",
        "    answer = str(row['Answer']).strip()\n",
        "    chat_format = f\"<|im_start|>user<|im_sep|>{question}<|im_end|><|im_start|>assistant<|im_sep|>{answer}<|im_end|>\"\n",
        "    lines.append({\"text\": chat_format})\n",
        "\n",
        "# JSONL formatÄ±nda kaydetmek istersen:\n",
        "with open(\"phi4_dataset.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in lines:\n",
        "        f.write(json.dumps(line, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# DeÄŸiÅŸken olarak da kullanabilirsin\n",
        "dataset = lines\n"
      ],
      "metadata": {
        "id": "W4CVM_L2P9R5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "7aBxm2oSR70C",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b2edb6-a39b-47ed-8e63-bee0d8fdb0c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': '<|im_start|>user<|im_sep|>What is the main purpose of Power Apps within the Power Platform?<|im_end|><|im_start|>assistant<|im_sep|>To allow users to build low-code/no-code custom business applications.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How do Power Apps and Power Automate complement each other in the Power Platform?<|im_end|><|im_start|>assistant<|im_sep|>Power Apps is used to build apps, while Power Automate enables automation of workflows within those apps.<|im_end|>'},\n",
              " {'text': \"<|im_start|>user<|im_sep|>What does 'within app context' mean in Power Automate licensing?<|im_end|><|im_start|>assistant<|im_sep|>It means flows can only access data and services directly related to the app that triggered them.<|im_end|>\"},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the difference between attended and unattended RPA in Power Automate?<|im_end|><|im_start|>assistant<|im_sep|>Attended RPA runs with user interaction, while unattended RPA runs autonomously.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What capabilities are enabled by Managed Environments in the Power Platform?<|im_end|><|im_start|>assistant<|im_sep|>Centralized governance, monitoring, and administration across environments.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Why would an organization use Power Apps per app license instead of Premium?<|im_end|><|im_start|>assistant<|im_sep|>For limited use cases where only one or two apps need to be run per user.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>When should a business consider using Power Pages?<|im_end|><|im_start|>assistant<|im_sep|>When creating external-facing websites that integrate with business data.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is a typical use case for Power Automate Hosted Process?<|im_end|><|im_start|>assistant<|im_sep|>Automating a critical business process on a Microsoft-hosted virtual machine.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How does Copilot Studio support conversational AI development?<|im_end|><|im_start|>assistant<|im_sep|>It allows users to design, test, and deploy custom copilots using natural language or a visual interface.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Why is licensing enforcement important in Power Platform environments?<|im_end|><|im_start|>assistant<|im_sep|>To ensure users and processes operate within the legal and technical usage limits.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Can a single Power Automate Process license be reused in multiple environments?<|im_end|><|im_start|>assistant<|im_sep|>No, a separate license is required for each environment.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the function of Power Platform connectors?<|im_end|><|im_start|>assistant<|im_sep|>They enable communication between Power Platform apps and external data/services.<|im_end|>'},\n",
              " {'text': \"<|im_start|>user<|im_sep|>What are 'child flows' in Power Automate?<|im_end|><|im_start|>assistant<|im_sep|>Flows that are triggered by other flows and don't require separate licenses.<|im_end|>\"},\n",
              " {'text': '<|im_start|>user<|im_sep|>Why is AI Builder important in business automation?<|im_end|><|im_start|>assistant<|im_sep|>It adds AI capabilities to apps and flows, enabling tasks like prediction and form processing.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the benefit of using Power Platform pay-as-you-go meters?<|im_end|><|im_start|>assistant<|im_sep|>Organizations only pay for actual usage, which is ideal for unpredictable user counts.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How does Power Apps help extend Dynamics 365 applications?<|im_end|><|im_start|>assistant<|im_sep|>By allowing customizations within the same environment as the licensed Dynamics 365 app.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What role does Dataverse play in Power Platform?<|im_end|><|im_start|>assistant<|im_sep|>It serves as the underlying data platform for storing and managing business data.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How does Power Pages handle user authentication?<|im_end|><|im_start|>assistant<|im_sep|>Authenticated users log in through identity providers for secure access.<|im_end|>'},\n",
              " {'text': \"<|im_start|>user<|im_sep|>What does the term 'capacity add-on' refer to in licensing?<|im_end|><|im_start|>assistant<|im_sep|>Additional resources like storage or service credits purchased on top of base licenses.<|im_end|>\"},\n",
              " {'text': '<|im_start|>user<|im_sep|>What restrictions exist when using Power Apps with Dynamics 365 Team Member licenses?<|im_end|><|im_start|>assistant<|im_sep|>They do not include rights to create or run standalone Power Apps.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How does Power Platform promote low-code development?<|im_end|><|im_start|>assistant<|im_sep|>By offering tools that enable app creation with minimal coding experience.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the purpose of a Power Automate per flow license?<|im_end|><|im_start|>assistant<|im_sep|>To license automation that can be used across an organization without user-based tracking.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Why is governance critical in Power Platform deployments?<|im_end|><|im_start|>assistant<|im_sep|>To manage compliance, control costs, and maintain security across environments.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Whatâ€™s the key distinction between Copilot Studio for Teams and Copilot Studio standalone?<|im_end|><|im_start|>assistant<|im_sep|>Teams version is limited to internal use in Teams, while standalone supports broader scenarios.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Why must businesses track Power Platform service limits?<|im_end|><|im_start|>assistant<|im_sep|>To avoid throttling and ensure performance and compliance.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the default message limit in Copilot Studio?<|im_end|><|im_start|>assistant<|im_sep|>25,000 billed messages per month per capacity pack.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What makes Power Platform suitable for both small businesses and enterprises?<|im_end|><|im_start|>assistant<|im_sep|>Its scalability, flexible licensing, and low-code approach.<|im_end|>'},\n",
              " {'text': \"<|im_start|>user<|im_sep|>What does it mean for licenses to be 'stackable' in Power Apps per app?<|im_end|><|im_start|>assistant<|im_sep|>Users can use multiple licenses to access different apps.<|im_end|>\"},\n",
              " {'text': '<|im_start|>user<|im_sep|>How does Power Platform help reduce shadow IT?<|im_end|><|im_start|>assistant<|im_sep|>It empowers users to build secure apps within IT-controlled environments.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the role of service credits in AI Builder?<|im_end|><|im_start|>assistant<|im_sep|>They are consumed when AI capabilities are used in apps or flows.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How does licensing differ between internal and external Power Pages users?<|im_end|><|im_start|>assistant<|im_sep|>Authenticated users are licensed per login, anonymous users per access.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Why would an organization need Dataverse capacity add-ons?<|im_end|><|im_start|>assistant<|im_sep|>To store more data than what is included in default entitlements.<|im_end|>'},\n",
              " {'text': \"<|im_start|>user<|im_sep|>What is the significance of the 'environment' in Power Platform?<|im_end|><|im_start|>assistant<|im_sep|>It provides isolated spaces for apps, flows, data, and governance.<|im_end|>\"},\n",
              " {'text': \"<|im_start|>user<|im_sep|>What is meant by 'plug-in' in Copilot Studio?<|im_end|><|im_start|>assistant<|im_sep|>Custom extensions that add new capabilities to copilots.<|im_end|>\"},\n",
              " {'text': '<|im_start|>user<|im_sep|>How does licensing differ for development vs production in Power Platform?<|im_end|><|im_start|>assistant<|im_sep|>Development environments may use trial licenses; production needs full licensing.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How do AI Builder credits relate to the type of AI model used?<|im_end|><|im_start|>assistant<|im_sep|>Different models consume credits at different rates based on complexity.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Can Power Platform be used without Dataverse?<|im_end|><|im_start|>assistant<|im_sep|>Yes, but functionality is limited compared to when Dataverse is used.<|im_end|>'},\n",
              " {'text': \"<|im_start|>user<|im_sep|>What is 'Process Mining' used for in Power Automate?<|im_end|><|im_start|>assistant<|im_sep|>To discover and optimize business process performance.<|im_end|>\"},\n",
              " {'text': '<|im_start|>user<|im_sep|>How is licensing compliance enforced in Managed Environments?<|im_end|><|im_start|>assistant<|im_sep|>All usage must have corresponding valid licenses.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What are examples of premium connectors?<|im_end|><|im_start|>assistant<|im_sep|>SAP, Salesforce, and Adobe Sign.<|im_end|>'},\n",
              " {'text': \"<|im_start|>user<|im_sep|>What does 'Dataverse for Teams' mean?<|im_end|><|im_start|>assistant<|im_sep|>A lightweight version of Dataverse embedded in Microsoft Teams.<|im_end|>\"},\n",
              " {'text': '<|im_start|>user<|im_sep|>How are Copilot Studio messages billed for Gen AI responses?<|im_end|><|im_start|>assistant<|im_sep|>Each Gen AI message counts as 2 billed messages.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Why is Copilot Studio important for internal customer support?<|im_end|><|im_start|>assistant<|im_sep|>It enables the creation of tailored AI chatbots for specific business needs.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How is licensing different for app creators versus end users?<|im_end|><|im_start|>assistant<|im_sep|>Creators need full licenses; users may only need per app access.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How are capacity packs assigned in Power Pages?<|im_end|><|im_start|>assistant<|im_sep|>They are assigned at the environment level.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How does Power Automate improve employee productivity?<|im_end|><|im_start|>assistant<|im_sep|>By automating repetitive tasks and workflows.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What are standard connectors used for?<|im_end|><|im_start|>assistant<|im_sep|>To connect with widely-used services like Outlook, SharePoint, or Twitter.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How do businesses manage Power Platform costs effectively?<|im_end|><|im_start|>assistant<|im_sep|>By choosing the right mix of licenses and monitoring usage regularly.<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the monthly cost of Power Apps Premium?<|im_end|><|im_start|>assistant<|im_sep|>$20 per user/month (or $12 with 2,000+ new licenses)<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What license types are available for Power Apps?<|im_end|><|im_start|>assistant<|im_sep|>Power Apps Premium, Power Apps per app, and Power Apps per app pay-as-you-go<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is included with Power Apps Premium?<|im_end|><|im_start|>assistant<|im_sep|>Unlimited custom apps, Power Pages websites, 500 AI Builder credits<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What are the Power Platform components covered in the licensing guide?<|im_end|><|im_start|>assistant<|im_sep|>Power Apps, Power Automate, Copilot Studio, Power Pages, AI Builder, Dataverse<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What does the Power Automate Premium license include?<|im_end|><|im_start|>assistant<|im_sep|>Unlimited cloud flows, 1 attended RPA bot, 5,000 AI Builder credits<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is a Power Automate Process license used for?<|im_end|><|im_start|>assistant<|im_sep|>Licenses a single unattended bot or business process<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How much does Power Automate Premium cost?<|im_end|><|im_start|>assistant<|im_sep|>$15 per user/month<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How much is the Power Automate Process license?<|im_end|><|im_start|>assistant<|im_sep|>$150 per bot/month<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What does the Power Automate Hosted Process include?<|im_end|><|im_start|>assistant<|im_sep|>Microsoft-hosted VM and unattended RPA bot<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the cost of Power Automate Hosted Process?<|im_end|><|im_start|>assistant<|im_sep|>$215 per bot/month<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the capacity of Process Mining license?<|im_end|><|im_start|>assistant<|im_sep|>100 GB of data/month per license<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How many messages does 1 Copilot Studio capacity pack provide?<|im_end|><|im_start|>assistant<|im_sep|>25,000 messages/month<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How much does Copilot Studio tenant license cost?<|im_end|><|im_start|>assistant<|im_sep|>$200 per tenant/month<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is a billed message in Copilot Studio?<|im_end|><|im_start|>assistant<|im_sep|>A message sent to or from the copilot triggering an action/response<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the message consumption rate for Gen AI in Copilot Studio?<|im_end|><|im_start|>assistant<|im_sep|>2 messages per Gen AI response<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the cost of Power Pages Authenticated users Tier 3?<|im_end|><|im_start|>assistant<|im_sep|>$50/pack for 100 users/month<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the cost of Power Pages Anonymous users Tier 3?<|im_end|><|im_start|>assistant<|im_sep|>$25/pack for 500 users/month<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the cost of Power Apps per app license?<|im_end|><|im_start|>assistant<|im_sep|>$5 per user/month<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the pay-as-you-go cost for Power Apps per app meter?<|im_end|><|im_start|>assistant<|im_sep|>$10 per active user/app/month<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What Dataverse capacity is included with Power Apps Premium?<|im_end|><|im_start|>assistant<|im_sep|>250 MB DB, 2 GB file<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What does AI Builder capacity add-on include?<|im_end|><|im_start|>assistant<|im_sep|>1 million service credits per month<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the max AI Builder credit capacity per tenant?<|im_end|><|im_start|>assistant<|im_sep|>1,000,000 credits<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Which Power Platform license includes full Dataverse access?<|im_end|><|im_start|>assistant<|im_sep|>Power Apps Premium<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is included in Managed Environments?<|im_end|><|im_start|>assistant<|im_sep|>Admin and governance at scale<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What are Power Platform pay-as-you-go meters?<|im_end|><|im_start|>assistant<|im_sep|>Meters that charge based on app usage per user/app<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Which license includes 5,000 AI Builder credits?<|im_end|><|im_start|>assistant<|im_sep|>Power Automate Premium<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is required to run Power Automate outside of Power Apps context?<|im_end|><|im_start|>assistant<|im_sep|>A full Power Automate license<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Can Power Pages be accessed anonymously?<|im_end|><|im_start|>assistant<|im_sep|>Yes, via Anonymous user licenses or meters<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What are the two types of users in Power Pages licensing?<|im_end|><|im_start|>assistant<|im_sep|>Authenticated and Anonymous users<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Is AI Builder included in Power Apps per app?<|im_end|><|im_start|>assistant<|im_sep|>Yes, with 250 service credits<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the use of Copilot Studio in Copilot for Microsoft 365?<|im_end|><|im_start|>assistant<|im_sep|>Create and manage plugins for Copilot<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Is there a free license for Copilot Studio bot authors?<|im_end|><|im_start|>assistant<|im_sep|>Yes, a $0 user license is required<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the purpose of Process Mining in Power Automate?<|im_end|><|im_start|>assistant<|im_sep|>Identify process improvement opportunities<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What services does Power Apps Basic include?<|im_end|><|im_start|>assistant<|im_sep|>Customizing Microsoft 365 and Teams apps<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Can Power Automate be used with Windows licenses?<|im_end|><|im_start|>assistant<|im_sep|>Yes, for attended desktop automation<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the storage capacity with Dataverse per 1 GB add-on?<|im_end|><|im_start|>assistant<|im_sep|>1 GB per purchase<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Is Power Automate Desktop free?<|im_end|><|im_start|>assistant<|im_sep|>Yes, but not intended for critical business functions<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What happens when a Copilot Studio tenant exceeds message capacity?<|im_end|><|im_start|>assistant<|im_sep|>Customers must purchase more packs<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What types of flows are included in Power Automate?<|im_end|><|im_start|>assistant<|im_sep|>Automated, instant, scheduled, desktop, business process<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Which flows do not need separate licenses in Power Automate?<|im_end|><|im_start|>assistant<|im_sep|>Child flows<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What connector types are available in Power Platform?<|im_end|><|im_start|>assistant<|im_sep|>Standard, Premium, Custom<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What licenses are required in Managed Environments?<|im_end|><|im_start|>assistant<|im_sep|>Full licenses for Power Apps, Automate, Pages, Copilot Studio<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the Power Pages meter rate for Authenticated users?<|im_end|><|im_start|>assistant<|im_sep|>$4 per user<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the Power Pages meter rate for Anonymous users?<|im_end|><|im_start|>assistant<|im_sep|>$0.30 per user<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>Is there a Dynamics 365 license that includes Power Apps?<|im_end|><|im_start|>assistant<|im_sep|>Yes, some Enterprise and Professional licenses<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How are AI Builder credits used?<|im_end|><|im_start|>assistant<|im_sep|>Consumed based on AI tasks like prediction, classification<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>How are Power Platform licenses sold?<|im_end|><|im_start|>assistant<|im_sep|>Via EA, CSP, Microsoft Partners, and Direct from Microsoft<|im_end|>'},\n",
              " {'text': '<|im_start|>user<|im_sep|>What licensing program covers government institutions?<|im_end|><|im_start|>assistant<|im_sep|>Enterprise Agreement for Government<|im_end|>'},\n",
              " {'text': \"<|im_start|>user<|im_sep|>What is Power Platform's primary purpose?<|im_end|><|im_start|>assistant<|im_sep|>Enable low-code/no-code development for business solutions<|im_end|>\"},\n",
              " {'text': '<|im_start|>user<|im_sep|>What is the licensing difference between per user and per app?<|im_end|><|im_start|>assistant<|im_sep|>Per user covers unlimited apps; per app covers one<|im_end|>'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][\"text\"]"
      ],
      "metadata": {
        "id": "C3mllnmCrPwo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2e3fe429-ea89-4e1a-ff71-861caca28a4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|im_start|>user<|im_sep|>What is the main purpose of Power Apps within the Power Platform?<|im_end|><|im_start|>assistant<|im_sep|>To allow users to build low-code/no-code custom business applications.<|im_end|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# JSONL olarak oluÅŸturduÄŸun listeyi HuggingFace Dataset'e dÃ¶nÃ¼ÅŸtÃ¼r\n",
        "hf_dataset = Dataset.from_list(dataset)\n"
      ],
      "metadata": {
        "id": "dLKcgaAarSoY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "95_Nn-89DhsL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "ceff0bd2ac5a4e788ee9e317211abf7a",
            "ec987602848a4998a83ebf77a1d30e94",
            "a83b40b647164c5594b48c0b096c04da",
            "76b258aefa354d17a2f1b7cf6c0d2d4f",
            "dbdd6235229544808990e5d9305b9759",
            "bc822ff5a097476b9bd1f3fc1579618b",
            "f13372ebd9a24bce9f844d43c9c46d93",
            "226f5597141549ac9abe5aeda55b8d05",
            "32e504f203224e0fa4d72be0aa7dadf0",
            "811433016ce44439bf69d3fc9699dcfb",
            "34adf4408d9b41f1a74565189ec01d1b"
          ]
        },
        "outputId": "09a87b62-4714-43f2-96c6-272211b4c90d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/98 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceff0bd2ac5a4e788ee9e317211abf7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = hf_dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 30,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sGp5XlG6dq"
      },
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "juQiExuBG5Bt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "814fd327debb4659b5c59be57aaad389",
            "7c31e2813a2f4840886eab034d821a9e",
            "675016b13afd47eb9165907d6775490b",
            "c9f66fdf68d041798a0f42e14039de21",
            "844a38f58b1f4e999ef47805a432279f",
            "6ef5673052964cf78afa5adfdaa28a85",
            "b13071a06c914b5e8a47091c3af823a9",
            "af6f5cd37d3248e49f82a3e9e3547779",
            "633860d56045495da25a0d6d4bef8e88",
            "1c80343ea9a84202bfc5862fb4e35f3c",
            "1e34742cba554b24bb6fa618110845a3"
          ]
        },
        "outputId": "829d5615-3734-4195-d34d-b3809efebfbb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/98 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "814fd327debb4659b5c59be57aaad389"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        }
      ],
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part=\"<|im_start|>user<|im_sep|>\",\n",
        "    response_part=\"<|im_start|>assistant<|im_sep|>\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv1NBUozV78l"
      },
      "source": [
        "We verify masking is actually done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LtsMVtlkUhja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8151c63a-9de7-4a7f-d972-b6d723dc69bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|im_start|>user<|im_sep|>Why would an organization use Power Apps per app license instead of Premium?<|im_end|><|im_start|>assistant<|im_sep|>For limited use cases where only one or two apps need to be run per user.<|im_end|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_rD6fl8EUxnG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a85391b-cd33-4a32-b43e-6a88ae904c3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                     For limited use cases where only one or two apps need to be run per user.<|im_end|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3enWUM0jV-jV"
      },
      "source": [
        "We can see the System and Instruction prompts are successfully masked!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ejIt2xSNKKp",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yqxqAZ7KJ4oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c5f560b-41e5-4794-d88f-560ef758a66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 98 | Num Epochs = 3 | Total steps = 30\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 65,536,000/4,000,000,000 (1.64% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 02:50, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.832700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.844000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.061700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.808300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4.602300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.975900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.100900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.570400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.808200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.864000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.042100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.906200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.969800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.990300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.320500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.577600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.774600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.861700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.400700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.585800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.525800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.867900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.756200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.547300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.996100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.603100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.314400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.312100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.280800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Unsloth_Studio.ipynb)**\n",
        "\n",
        "We use `min_p = 0.1` and `temperature = 1.5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kR3gIAX-SM2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ccbc26-04b7-4c21-f38f-99a8930ef744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Power Automate is used for automating workflows and business processes.\n"
          ]
        }
      ],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import re\n",
        "\n",
        "tokenizer = get_chat_template(tokenizer, chat_template = \"phi-4\")\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "def parse_phi_chat(text):\n",
        "    pattern = r\"<\\|im_start\\|>(user|assistant)<\\|im_sep\\|>(.*?)<\\|im_end\\|>\"\n",
        "    matches = re.findall(pattern, text, re.DOTALL)\n",
        "    return [{\"role\": role.strip(), \"content\": content.strip()} for role, content in matches]\n",
        "\n",
        "text = dataset[0][\"text\"]\n",
        "messages = parse_phi_chat(text)\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True,\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids = inputs,\n",
        "    max_new_tokens = 100,\n",
        "    use_cache = True,\n",
        "    temperature = 1.0,\n",
        "    top_p = 0.95,\n",
        ")\n",
        "\n",
        "#Sadece Ã¼retilen kÄ±smÄ± decode et\n",
        "generated = outputs[0][inputs.shape[-1]:]\n",
        "print(tokenizer.decode(generated, skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see The generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l4xoN-njyjpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§ª Inference on Custom Dataset and Exporting Model Outputs to CSV\n",
        "\n",
        "This section performs **inference using a fine-tuned language model** (e.g., Phi-4 with LoRA adapters) on a custom dataset containing chat-style prompts and expected responses. The model's outputs are collected and saved into a CSV file for further analysis.\n",
        "\n",
        "### ðŸ“ Dataset Format\n",
        "Each entry in the dataset is a single string with special formatting using tokens:\n",
        "\n",
        "<|im_start|>user<|im_sep|>QUESTION<|im_end|>\n",
        "\n",
        "<|im_start|>assistant<|im_sep|>EXPECTED_ANSWER<|im_end|>\n",
        "\n",
        "\n",
        "\n",
        "### ðŸŽ¯ Goal\n",
        "- Extract the `QUESTION` part from each dataset item.\n",
        "- Generate a response using the model.\n",
        "- Compare it with the `EXPECTED_ANSWER` (optional).\n",
        "- Save all results into a `model_outputs.csv` file.\n",
        "\n",
        "### ðŸ“¤ Output CSV Columns\n",
        "- **question**: User input extracted from the dataset.\n",
        "- **expected_answer**: The reference assistant answer.\n",
        "- **generated_answer**: The modelâ€™s generated response.\n",
        "\n",
        "This step is essential for validating how well the model performs on custom examples and helps in error analysis or evaluation.\n"
      ],
      "metadata": {
        "id": "5cp5x41Pz3kT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import openpyxl\n",
        "from transformers import TextStreamer\n",
        "from openpyxl import Workbook\n",
        "\n",
        "results = []\n",
        "\n",
        "for i, row in enumerate(dataset):\n",
        "    text = row[\"text\"]\n",
        "\n",
        "    # Soruyu Ã§Ä±kar\n",
        "    try:\n",
        "        question = text.split(\"<|im_sep|>\")[1].split(\"<|im_end|>\")[0].strip()\n",
        "    except:\n",
        "        print(f\"Parse hatasÄ± satÄ±r {i}: {text}\")\n",
        "        continue\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": question}]\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Modelden yanÄ±t al\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs,\n",
        "            max_new_tokens=128,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            use_cache=True,\n",
        "        )\n",
        "\n",
        "    # Tokenleri Ã§Ã¶z\n",
        "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    # Sadece assistant cevabÄ±nÄ± al\n",
        "    if \"<|im_start|>assistant<|im_sep|>\" in decoded_output:\n",
        "        generated_answer = decoded_output.split(\"<|im_start|>assistant<|im_sep|>\")[-1].split(\"<|im_end|>\")[0].strip()\n",
        "    else:\n",
        "        generated_answer = decoded_output.strip()\n",
        "\n",
        "    # Referans cevabÄ± al\n",
        "    try:\n",
        "        expected_answer = text.split(\"<|im_start|>assistant<|im_sep|>\")[1].split(\"<|im_end|>\")[0].strip()\n",
        "    except:\n",
        "        expected_answer = \"\"\n",
        "\n",
        "    results.append((question, expected_answer, generated_answer))\n",
        "\n",
        "\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"Model CevaplarÄ±\"\n",
        "\n",
        "ws.append([\"question\", \"expected_answer\", \"generated_answer\"])\n",
        "\n",
        "# Datas\n",
        "for row in results:\n",
        "    ws.append(row)\n",
        "\n",
        "wb.save(\"model_outputs.xlsx\")\n",
        "print(\"âœ… Excel dosyasÄ± 'model_outputs.xlsx' olarak kaydedildi.\")\n"
      ],
      "metadata": {
        "id": "qlIA38WFyj7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3509063-a3de-47e2-9519-8a16e4eb08b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Excel dosyasÄ± 'model_outputs.xlsx' olarak kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "upcOlWe7A1vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fa13dd-c225-4e34-8c6a-71efd7aad711"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/vocab.json',\n",
              " 'lora_model/merges.txt',\n",
              " 'lora_model/added_tokens.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MKX_XKs_BNZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902c8ea1-b376-448c-c97a-8f4997e19f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By adjusting settings and preferences.<|im_end|>\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"How can users customize Copilot behavior?\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(\n",
        "    input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "    use_cache = True, temperature = 1.5, min_p = 0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\",  # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit=load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Google Drive Connect"
      ],
      "metadata": {
        "id": "LHzjm3jvxhns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# 1. Google Drive'Ä± mount et\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Kaynak klasÃ¶r (modelin bulunduÄŸu yer)\n",
        "source_folder = \"/content/lora_model\"  # lora_model klasÃ¶rÃ¼n buradaysa\n",
        "drive_folder = \"/content/drive/MyDrive/fine_tuned_phi4_2\"\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "# 3. Kopyalanacak dosyalarÄ±n listesi\n",
        "files_to_copy = [\n",
        "    \"adapter_model.safetensors\",\n",
        "    \"adapter_config.json\",\n",
        "    \"tokenizer.json\",\n",
        "    \"tokenizer_config.json\",\n",
        "    \"vocab.json\",\n",
        "    \"merges.txt\",\n",
        "    \"special_tokens_map.json\"\n",
        "]\n",
        "\n",
        "# 4. DosyalarÄ± kopyala\n",
        "for file_name in files_to_copy:\n",
        "    source_path = os.path.join(source_folder, file_name)\n",
        "    if os.path.exists(source_path):\n",
        "        shutil.copy(source_path, drive_folder)\n",
        "        print(f\"âœ… {file_name} Drive'a kopyalandÄ±.\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ {file_name} bulunamadÄ±, atlandÄ±.\")\n",
        "\n",
        "print(\"ðŸ“ TÃ¼m iÅŸlemler tamamlandÄ±.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uen5f80xhU0",
        "outputId": "8b984be8-2c5c-4d4a-a68b-f00fdb323c05"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… adapter_model.safetensors Drive'a kopyalandÄ±.\n",
            "âœ… adapter_config.json Drive'a kopyalandÄ±.\n",
            "âœ… tokenizer.json Drive'a kopyalandÄ±.\n",
            "âœ… tokenizer_config.json Drive'a kopyalandÄ±.\n",
            "âœ… vocab.json Drive'a kopyalandÄ±.\n",
            "âœ… merges.txt Drive'a kopyalandÄ±.\n",
            "âœ… special_tokens_map.json Drive'a kopyalandÄ±.\n",
            "ðŸ“ TÃ¼m iÅŸlemler tamamlandÄ±.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8fvG9MhYxpgr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d61846e6c58e46719c2f74760fa02871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b9d90c4e3054059af225683025c2b3a",
              "IPY_MODEL_cb2f3f61c06c4781936194ab86fc210e",
              "IPY_MODEL_54f3113b4b4648649a6319405aebaa98"
            ],
            "layout": "IPY_MODEL_c288924e814b4e5384cbe8db750270f8"
          }
        },
        "3b9d90c4e3054059af225683025c2b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8177bf13a6094797959d4fc7c630d52a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_64252cef56984119938d8cf35c600199",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "cb2f3f61c06c4781936194ab86fc210e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f31d49fc7dbc4d16a60da369ff27aab5",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2269879049da4663a0ab2da8ce3174e1",
            "value": 3
          }
        },
        "54f3113b4b4648649a6319405aebaa98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19893acc6a5d4d7fb26781d44fbc37ad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_135dcf1fb51a4aa68ee20428386129ab",
            "value": "â€‡3/3â€‡[00:57&lt;00:00,â€‡16.48s/it]"
          }
        },
        "c288924e814b4e5384cbe8db750270f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8177bf13a6094797959d4fc7c630d52a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64252cef56984119938d8cf35c600199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f31d49fc7dbc4d16a60da369ff27aab5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2269879049da4663a0ab2da8ce3174e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19893acc6a5d4d7fb26781d44fbc37ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "135dcf1fb51a4aa68ee20428386129ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceff0bd2ac5a4e788ee9e317211abf7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec987602848a4998a83ebf77a1d30e94",
              "IPY_MODEL_a83b40b647164c5594b48c0b096c04da",
              "IPY_MODEL_76b258aefa354d17a2f1b7cf6c0d2d4f"
            ],
            "layout": "IPY_MODEL_dbdd6235229544808990e5d9305b9759"
          }
        },
        "ec987602848a4998a83ebf77a1d30e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc822ff5a097476b9bd1f3fc1579618b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f13372ebd9a24bce9f844d43c9c46d93",
            "value": "Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]â€‡(num_proc=2):â€‡100%"
          }
        },
        "a83b40b647164c5594b48c0b096c04da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_226f5597141549ac9abe5aeda55b8d05",
            "max": 98,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32e504f203224e0fa4d72be0aa7dadf0",
            "value": 98
          }
        },
        "76b258aefa354d17a2f1b7cf6c0d2d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811433016ce44439bf69d3fc9699dcfb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_34adf4408d9b41f1a74565189ec01d1b",
            "value": "â€‡98/98â€‡[00:01&lt;00:00,â€‡54.81â€‡examples/s]"
          }
        },
        "dbdd6235229544808990e5d9305b9759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc822ff5a097476b9bd1f3fc1579618b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13372ebd9a24bce9f844d43c9c46d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "226f5597141549ac9abe5aeda55b8d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e504f203224e0fa4d72be0aa7dadf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "811433016ce44439bf69d3fc9699dcfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34adf4408d9b41f1a74565189ec01d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "814fd327debb4659b5c59be57aaad389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c31e2813a2f4840886eab034d821a9e",
              "IPY_MODEL_675016b13afd47eb9165907d6775490b",
              "IPY_MODEL_c9f66fdf68d041798a0f42e14039de21"
            ],
            "layout": "IPY_MODEL_844a38f58b1f4e999ef47805a432279f"
          }
        },
        "7c31e2813a2f4840886eab034d821a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef5673052964cf78afa5adfdaa28a85",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b13071a06c914b5e8a47091c3af823a9",
            "value": "Mapâ€‡(num_proc=2):â€‡100%"
          }
        },
        "675016b13afd47eb9165907d6775490b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af6f5cd37d3248e49f82a3e9e3547779",
            "max": 98,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_633860d56045495da25a0d6d4bef8e88",
            "value": 98
          }
        },
        "c9f66fdf68d041798a0f42e14039de21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c80343ea9a84202bfc5862fb4e35f3c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1e34742cba554b24bb6fa618110845a3",
            "value": "â€‡98/98â€‡[00:00&lt;00:00,â€‡137.77â€‡examples/s]"
          }
        },
        "844a38f58b1f4e999ef47805a432279f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef5673052964cf78afa5adfdaa28a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b13071a06c914b5e8a47091c3af823a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af6f5cd37d3248e49f82a3e9e3547779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "633860d56045495da25a0d6d4bef8e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c80343ea9a84202bfc5862fb4e35f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e34742cba554b24bb6fa618110845a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}